# (c) 2020 Sylvain Le Groux <slegroux@ccrma.stanford.edu>

export EXP_LOG="logs/minilibripeech.log"
# today=$(date +'%Y%m%d')
# today=20200928
today='en/minilibrispeech'
# general data and repo settings
data=experiments/${today}/data
exp=experiments/${today}/exp
data_root="/home/syl20/data/en/librispeech"
libri="${data_root}/LibriSpeech"
datasets="${libri}/dev-clean-2 ${libri}/train-clean-5"
train=${data}/train_clean_5
test=${data}/dev_clean_2
# dev=${data}/dev

# L
unk="<UNK>"
lang='en'
lexicon="${data_root}/lm/librispeech-lexicon.txt"
dict=${data}/dict
lang_dir=${data}/lang

# G
corpus_train=${train}/text
corpus_dev=${test}/text
lm_dir=${data}/lm
lm_train=${lm_dir}/train.txt
# ! test->dev
lm_dev=${lm_dir}/dev.txt
lm_order=3
limit_unk_history=true
lm_name=$(basename ${train})_${lm_order}g
lm=${lang_dir}_${lm_name}

# HMM
# TODO: triphone clustering params
nj_mono=8
lang_test=${lm}
boost_silence=1.0
subset=1000
mono=${exp}/mono
tri1=${exp}/tri1
tri2=${exp}/tri2
tri3=${exp}/tri3

# i-vector
nj_ivec_extract=6
dataset=${data}/train
tri3=${exp}/tri3
online_cmvn_iextractor=false
# i-vector model extracted from data
# ivec_model=${exp}/ivector_mdl
ivec_model=/home/syl20/data/en/librispeech/models/0013_librispeech_v1/exp/nnet3_cleaned
ivec_extractor=${ivec_model}/extractor
# nj=6 #c.f. ivec train script (nj*threads*)

# DNN
# build lang chain
lang_chain=${lang_dir}_chain
tree=${exp}/chain/tree #TODO(sylvain): change to chain2

# train model on sp_vp_hires
# dnn_architecture="tdnnf_1d_tedlium"
dnn_architecture="tdnnf_1k_minilibrispeech"
mdl=${exp}/chain/${dnn_architecture}
train_dnn=${train}_sp_vp_hires
lat_dir=${tri3}_sp_ali_lats
ivec_data=${train_dnn}/ivectors
num_epochs=10
n_gpu=2
train_stage=-10
remove_egs=true

graph=${exp}/chain/tree/graph_${lm_name}

# DNN test
decode_name=decode_${lm_name} # needs to be a subset of model dir
dnn_test=${test}
# decode_{lm_name}_{test_data}_{n_epochs}
decode_test_name=${decode_name}_test_epochs${num_epochs}

# RNNLM
rnnlm_dir=${exp}/rnnlm
rnnlm_data=${data}/rnnlm
wordlist=${data}/lang_chain/words.txt
embedding_dim=800 #800
lstm_rpd=200
lstm_nrpd=200
rnn_stage=0
rnn_train_stage=-10
rnn_epochs=20
rnn_gpu=1

# RNNLM Test
rescore_ngram_order=4
rnnlm_test=${test}
decode_og=${mdl}/${decode_test_name}
decode_rnnlm=${decode_og}_rnnlm
