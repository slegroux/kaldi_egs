# (c) 2020 Sylvain Le Groux <slegroux@ccrma.stanford.edu>

today=$(date +'%Y%m%d')

# DATA PREP
# -INPUT
lang='es'
data_id='webex_clean'
export EXP_LOG="logs/es_${data_id}.log"
# general data and repo settings
data=experiments/${lang}/${data_id}/data
exp=experiments/${lang}/${data_id}/exp

es_root="/home/syl20/data/es"
webex_root="${es_root}/webex"

webex_tst_root="${webex_root}/test_dataset/ES-1"
webex_tst_csv="${webex_tst_root}/ES-1.trans.txt"
webex_tst_audio="${webex_tst_root}/flac"

webex_train_root="${webex_root}/small30"
webex_train_csv="${webex_train_root}/small30_transcript.csv"
webex_train_audio="${webex_train_root}/flac"

# -OUTPUT
n_hours=30
train=${data}/small_${n_hours}
test=${data}/es-1
dev=${data}/es-1 #TODO(slg): use proper dev set

# L
# -INPUT
unk="<UNK>"
lang='es'
lexicon="${es_root}/lm/santiago.txt"
# -OUTPUT
dict=${data}/dict
lang_dir=${data}/lang

# G
# -INPUT
# lm_corpus="${data_root}/lm/OpenSubtitles/OpenSubtitles.en-es.es"
corpus_train=${train}/text
corpus_dev=${dev}/text 

lm_dir=${data}/lm
lm_train=${lm_dir}/train.txt
lm_dev=${lm_dir}/dev.txt

lm_order="3 4 5"
limit_unk_history=true

tg_name=$(basename ${train})_3g
fg_name=$(basename ${train})_4g
qg_name=$(basename ${train})_5g
# lm_name=$(basename ${train})_${lm_order}g
# - OUTPUT
lm=${lang_dir}_${tg_name}


# HMM
# -INPUT
nj_mono=8
lang_test=${lm}
boost_silence=1.0
subset=1000
# cluster_thres=
# n_gaussians=
# n_leafs=
#  -OUTPUT
mono=${exp}/mono
tri1=${exp}/tri1
tri2=${exp}/tri2
tri3=${exp}/tri3

# I-VECTOR
# -INPUT
nj_ivec_extract=5
n_threads=4
n_processes=2
tri3=${exp}/tri3
online_cmvn_iextractor=false
subset_factor=5
# -OUTPUT
ivec_model=${exp}/ivector_mdl # i-vector model extracted from data
# ivec_model=/home/syl20/data/en/librispeech/models/0013_librispeech_v1/exp/nnet3_cleaned # i-vector pre-trained
ivec_extractor=${ivec_model}/extractor

# DNN
# build lang chain
lang_chain=${lang_dir}_chain
tree=${exp}/chain/tree #TODO(sylvain): change to chain2

# train model on sp_vp_hires
# dnn_architecture="tdnnf_1d_tedlium"
dnn_architecture="tdnnf_1k_minilibrispeech"
mdl=${exp}/chain/${dnn_architecture}_${n_hours}
train_dnn=${train}_sp_vp_hires
lat_dir=${tri3}_sp_ali_lats
ivec_data=${train_dnn}/ivectors
num_epochs=10
n_gpu=8
train_stage=-10
remove_egs=true
graph=${exp}/chain/tree/graph_${tg_name}


# DNN test
test_data=$(basename ${test})
# decode_{lm_name}_{test_data}_{n_epochs} # folder is automatically created under model dir 
decode_test_name=decode_${tg_name}_test_epochs${num_epochs}

# N-GRAM RESCORING
old_lm=${lm}
# new_lm=${lang_dir}_${fg_name}
new_lm=${lang_dir}_${fg_name}


# RNNLM
rnnlm_dir=${exp}/rnnlm
rnnlm_data=${data}/rnnlm
wordlist=${data}/lang_chain/words.txt
rnnlm_embedding_dim=1024
lstm_rpd=256
lstm_nrpd=256
rnn_stage=0
rnn_train_stage=-10
rnn_epochs=4
rnn_gpu=1


# RNNLM Test
rescore_ngram_order=4
rnnlm_test=${test}
decode_og=${mdl}/${decode_test_name}
decode_rnnlm=${decode_og}_rnnlm

# ONLINE DECODING
online_mdl=${mdl}_online
archive_name="${lang}_${data_id}_${n_hours}h_sp_vp_3g_epoch${num_epochs}.tar.gz"
online_decode_dir=${mdl}_online/decode_${tg_name}_test_epochs${num_epochs}
samp_freq=16000
online_conf=${mdl}_online/conf/online.conf
port_num=5050
# test_audio=/home/syl20/data/en/librispeech/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac
# test_transcript=$(cat /home/syl20/data/en/librispeech/LibriSpeech/test-clean/1089/134686/1089-134686.trans.txt |grep 1089-134686-0000)
