# (c) 2020 Sylvain Le Groux <slegroux@ccrma.stanford.edu>

export EXP_LOG="logs/libripeech.log"
# today=$(date +'%Y%m%d')
# today=20200928

# DATA PREP
today='en/librispeech'
# general data and repo settings
data=experiments/${today}/data
exp=experiments/${today}/exp
data_root="/home/syl20/data/en/librispeech"
libri="${data_root}/LibriSpeech"
datasets="${libri}/train-clean-5 ${libri}/train-clean-100 ${libri}/train-clean-360 ${libri}/train-other-500 \
    ${libri}/test-clean ${libri}/test-other \
    ${libri}/dev-clean-2 ${libri}/dev-clean ${libri}/dev-other"

train=${data}/train_clean_100
test=${data}/test_clean
dev=${data}/dev_clean

# L
unk="<UNK>"
lang='en'
lexicon="${data_root}/lm/librispeech-lexicon.txt"
dict=${data}/dict
lang_dir=${data}/lang

# G
corpus_train=${train}/text
corpus_dev=${dev}/text

lm_dir=${data}/lm
lm_train=${lm_dir}/train.txt
lm_dev=${lm_dir}/dev.txt

lm_order="3 4 5"
limit_unk_history=true

tg_name=$(basename ${train})_3g
fg_name=$(basename ${train})_4g
qg_name=$(basename ${train})_5g
# lm_name=$(basename ${train})_${lm_order}g
lm=${lang_dir}_${tg_name}


# HMM
# TODO: triphone clustering params
nj_mono=8
lang_test=${lm}
boost_silence=1.0
subset=1000
mono=${exp}/mono
tri1=${exp}/tri1
tri2=${exp}/tri2
tri3=${exp}/tri3

# i-vector
nj_ivec_extract=6
dataset=${data}/train
tri3=${exp}/tri3
online_cmvn_iextractor=false
subset_factor=10
# i-vector model extracted from data
ivec_model=${exp}/ivector_mdl
# ivec_model=/home/syl20/data/en/librispeech/models/0013_librispeech_v1/exp/nnet3_cleaned
ivec_extractor=${ivec_model}/extractor
# nj=6 #c.f. ivec train script (nj*threads*)

# DNN
# build lang chain
lang_chain=${lang_dir}_chain
tree=${exp}/chain/tree #TODO(sylvain): change to chain2

# train model on sp_vp_hires
# dnn_architecture="tdnnf_1d_tedlium"
dnn_architecture="tdnnf_1d_librispeech"
mdl=${exp}/chain/${dnn_architecture}
train_dnn=${train}_sp_vp_hires
lat_dir=${tri3}_sp_ali_lats
ivec_data=${train_dnn}/ivectors
num_epochs=10
n_gpu=8
train_stage=-10
remove_egs=true
graph=${exp}/chain/tree/graph_${tg_name}

# DNN test
test_data=$(basename ${test})
# decode_{lm_name}_{test_data}_{n_epochs} # folder is automatically created under model dir 
decode_test_name=decode_${tg_name}_test_epochs${num_epochs}

# N-GRAM RESCORING
old_lm=${lm}
# new_lm=${lang_dir}_${fg_name}
new_lm=${lang_dir}_${fg_name}


# RNNLM
rnnlm_dir=${exp}/rnnlm
rnnlm_data=${data}/rnnlm
wordlist=${data}/lang_chain/words.txt
rnnlm_embedding_dim=1024
lstm_rpd=256
lstm_nrpd=256
rnn_stage=0
rnn_train_stage=-10
rnn_epochs=4
rnn_gpu=1

# RNNLM Test
rescore_ngram_order=4
rnnlm_test=${test}
decode_og=${mdl}/${decode_test_name}
decode_rnnlm=${decode_og}_rnnlm
